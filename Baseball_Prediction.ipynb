{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseball Pitch Prediction</h1>\n",
    "\n",
    "<h3>Author:  Le Phan</h3>\n",
    " \n",
    "<h4>Date: October 11, 2019</h4>\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Data Processing](#process)\n",
    "3. [Feature Engineering](#features)\n",
    "4. [Classification Method](#model)\n",
    "5. [Results](#res)\n",
    "6. [Future Considerations](#futures)\n",
    "7. [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "<h2>1. Introduction</h2>\n",
    "\n",
    "Baseball is one of the most popular sports in America. Top performing players could earn astronomical contract value in addition to sponsorship deals with leading consumer product brands. Most recently, Many Machado signed a 10-year deal with the Padres for a whopping $300 millions. To help understand player performance, the Major Baseball League (MLB) provides detailed data set that measures every aspect of the game through its PITCHf/x system. Pitch related data is extremely important as it helps baseball teams measure their players' performances. It can also be used to predict the pitching pattern of an opposing team during a game--a significant strategy advantage.\n",
    "\n",
    "This data analysis project examines the 2011 pitch data set provided by Swish Analytics, a sport analytics company, and builds machine learning models that can be used to for pitch prediction during a game. [Section 2](#process) discusses the data exploration and transformation process. [Section 3](#features) goes over the feature engineering steps derived from a subset of features taken from the original data. Machine learning models and results are discussed in [Section 4](#model) and [Section 5](#res)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process'></a>\n",
    "<h2>2. Data Processing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is a record of 720,000 pitches made in the year 2011. It contains pre-pitch information such as the current ball/strike count, whether the pitcher is left-handed or right-handed, the presence of runner on first, second, and third base. These are important features as they influence a pitcher's strategy. For instance, if there are runners on all three bases and the current ball/strike count is 3/2 with 2 outs then the pitcher has greater incentive not to let the batter walk and might attemp to strike the batter out by throwing more centered pitch. Other post-pitch information that are also useful includes the horizontal/vertical position of the pitch and its velocity. These features will be use to engineer additional features in the next section. But let's first load the data and examine some descriptive statistics. See the [Appendix](#appendix) for a full list of features used and their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1096\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1096\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1096\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1096' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n",
       "  var css_urls = [];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1096\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1096\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1096\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1096' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1096\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 144\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"uid\", \"game_pk\", \"inning\", \"top\", \"at_bat_num\", \"pcount_at_bat\", \"pcount_pitcher\",\n",
    "         \"balls\", \"strikes\", \"fouls\", \"outs\", \"batter_id\", \"pitcher_id\", \"p_throws\",\n",
    "         \"x\", \"y\", \"start_speed\", \"pitch_type\", \"on_1b\", \"on_2b\", \"on_3b\"]\n",
    "\n",
    "df = pd.read_csv(\"pitches.zip\", usecols=names, index_col=\"uid\")\n",
    "len(df.pitcher_id.unique()) # 662 pitchers in 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # (718961, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical data\n",
    "df[[\"batter_id\", \"p_throws\", \"pitch_type\"]] = df[[\"batter_id\", \"p_throws\", \"pitch_type\"]].astype(\"category\")\n",
    "# binarize \n",
    "df[[\"on_1b\", \"on_2b\", \"on_3b\"]] = np.where(df[[\"on_1b\", \"on_2b\", \"on_3b\"]] > 0, 1, 0)\n",
    "# add pitcher-count pair\n",
    "df[\"pc_pair\"]  = df[\"pitcher_id\"].astype(str) + \"_\" + df[\"balls\"].astype(str) + df[\"strikes\"].astype(str)\n",
    "# add balls-strike count\n",
    "df[\"bs_count\"] = df[\"balls\"].astype(str) + df[\"strikes\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     662.000000\n",
       "mean     1086.043807\n",
       "std      1044.893803\n",
       "min         5.000000\n",
       "25%       251.250000\n",
       "50%       814.500000\n",
       "75%      1332.000000\n",
       "max      4301.000000\n",
       "Name: pitcher_id, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pitcher_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given there are 662 pitchers in the data set, we want to filter out pitchers who do not pitch regularly.  Since there are 162 games for each team per MLB season, it is assumed that pitchers who pitched less than 1000 times (slightly below the mean) in 2011 are **relieve** pitchers who entered the game after the starting pitcher is removed--often due to injuries or fatigue. This filter reduces the pitcher count to 255. From here, we can exmine the distribution of each type of pitch over the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"dd92b201-57d0-41bf-a876-06e416dce808\" data-root-id=\"1097\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"e2228537-8fe7-4642-9359-248b384689bf\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1108\",\"type\":\"CategoricalAxis\"}],\"center\":[{\"id\":\"1111\",\"type\":\"Grid\"},{\"id\":\"1116\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1112\",\"type\":\"LinearAxis\"}],\"plot_height\":250,\"renderers\":[{\"id\":\"1133\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1098\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1123\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1100\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1104\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1102\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1106\",\"type\":\"LinearScale\"}},\"id\":\"1097\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1146\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1113\",\"type\":\"BasicTicker\"}},\"id\":\"1112\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"data\":{\"top\":[179501,76732,63125,62847,59184,45115,33284,8030,7396,4431,2495,421,247,131,115,12,2,1],\"x\":[\"FF\",\"SL\",\"FT\",\"SI\",\"CH\",\"CU\",\"FC\",\"FS\",\"KC\",\"KN\",\"IN\",\"PO\",\"FO\",\"EP\",\"FA\",\"UN\",\"AB\",\"SC\"]},\"selected\":{\"id\":\"1149\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1150\",\"type\":\"UnionRenderers\"}},\"id\":\"1130\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1150\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"grid_line_color\":null,\"ticker\":{\"id\":\"1109\",\"type\":\"CategoricalTicker\"}},\"id\":\"1111\",\"type\":\"Grid\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1148\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1109\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"1144\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1109\",\"type\":\"CategoricalTicker\"}},\"id\":\"1108\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1120\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1106\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1104\",\"type\":\"CategoricalScale\"},{\"attributes\":{},\"id\":\"1144\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"1148\",\"type\":\"BoxAnnotation\"}},\"id\":\"1119\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"callback\":null,\"factors\":[\"FF\",\"SL\",\"FT\",\"SI\",\"CH\",\"CU\",\"FC\",\"FS\",\"KC\",\"KN\",\"IN\",\"PO\",\"FO\",\"EP\",\"FA\",\"UN\",\"AB\",\"SC\"]},\"id\":\"1100\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1118\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":\"Pitch Type Counts\"},\"id\":\"1098\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"1102\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1146\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1117\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1149\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1130\",\"type\":\"ColumnDataSource\"}},\"id\":\"1134\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1130\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1131\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1132\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1134\",\"type\":\"CDSView\"}},\"id\":\"1133\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1131\",\"type\":\"VBar\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1117\",\"type\":\"PanTool\"},{\"id\":\"1118\",\"type\":\"WheelZoomTool\"},{\"id\":\"1119\",\"type\":\"BoxZoomTool\"},{\"id\":\"1120\",\"type\":\"SaveTool\"},{\"id\":\"1121\",\"type\":\"ResetTool\"},{\"id\":\"1122\",\"type\":\"HelpTool\"}]},\"id\":\"1123\",\"type\":\"Toolbar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"x\"}},\"id\":\"1132\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1122\",\"type\":\"HelpTool\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1113\",\"type\":\"BasicTicker\"}},\"id\":\"1116\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1121\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1113\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"1097\"]},\"title\":\"Bokeh Application\",\"version\":\"1.3.4\"}};\n",
       "  var render_items = [{\"docid\":\"e2228537-8fe7-4642-9359-248b384689bf\",\"roots\":{\"1097\":\"dd92b201-57d0-41bf-a876-06e416dce808\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1097"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter out pitcher with less than 1000 pitches\n",
    "df = df.groupby(\"pitcher_id\").filter(lambda x: len(x) > 1000)  # 255 pitchers\n",
    "\n",
    "pitches = df.pitch_type.value_counts()\n",
    "types = list(pitches.index)\n",
    "counts = list(pitches.values)\n",
    "\n",
    "# set the x_range to the list of categories\n",
    "p = figure(x_range=types, plot_height=250, title=\"Pitch Type Counts\")\n",
    "p.vbar(x=types, top=counts, width=.9)\n",
    "\n",
    "# set some properties to make plot look better\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the barplot, it is obvious that fastballs are the popular type of pitch. Although there are 18 pitch categories, the distribution skew toward a hand full of pitch types. Thus, it makes sense to put the categories that occur more frequently in their own general buckets while relabeling the low frequencies pitch types as \"others\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pitch_types with general labels\n",
    "fastballs = dict.fromkeys([\"FF\", \"FT\", \"FC\", \"FS\"], \"FB\")\n",
    "knuckleballs = dict.fromkeys([\"KC\", \"KN\"], \"KB\")\n",
    "otherballs = dict.fromkeys([\"PO\", \"FO\", \"EP\", \"FA\", \"UN\", \"AB\", \"SC\", np.nan], \"OB\")\n",
    "df[\"pitch_type\"] = df.pitch_type.replace(fastballs)\n",
    "df[\"pitch_type\"] = df.pitch_type.replace(knuckleballs)\n",
    "df[\"pitch_type\"] = df.pitch_type.replace(otherballs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "<h2>3. Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section use a subset of the original features to derive additional insights into factors that might be useful in predicting the next pitch. See the [Appendix](#appendix) for a full list of added features. Since each pitcher is different and have different preference to the type of ball he will throw, we will add the pitcher's historical pitch percentages of each type (i.e., fast, sinker, slider, curve, changeup, knuckle). This is accomplished with the helper function `_get_pitch_pct` which is called by the `add_pitch_pct` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pitch_pct(dff):  \n",
    "    \"\"\"Compute pitcher's career percentages for each pitch type.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    d: dictionary with (pithcer_id, pitch_type) as key and percentage as value\n",
    "    \"\"\"\n",
    "    x = dff.groupby(\"pitcher_id\").agg({\"pitch_type\": \"count\"})\n",
    "    y = dff.groupby([\"pitcher_id\", \"pitch_type\"]).agg({\"pitch_type\": \"count\"})\n",
    "    z = y.div(x, axis=1)\n",
    "    d = {}\n",
    "    for i in range(len(z)):\n",
    "        d[z.index[i]] = z.values[i][0]\n",
    "    return d\n",
    "\n",
    "def add_pitch_pct(dff, pct_list):\n",
    "    \"\"\"Add careeer percentages features to dataframe.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    pct_list: list of 2-tuple of strings representing the pitch type percentages\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    dff: pd.DataFrame with added career features\n",
    "    \"\"\"\n",
    "    career_pct = _get_pitch_pct(dff)\n",
    "    for el in pct_list:\n",
    "        dff[el[0]] = dff.pitcher_id.map(lambda x: career_pct.get((x, el[1]), 0))\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 223 ms, total: 5.21 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# percentage list for each type of pitch\n",
    "career_features = [(\"fast_pct\", \"FB\"), (\"sinker_pct\", \"SI\"), \n",
    "           (\"slider_pct\", \"SL\"), (\"curve_pct\", \"CU\"), \n",
    "           (\"changeup_pct\", \"CH\"), (\"knuckle_pct\", \"KB\"), \n",
    "           (\"other_pct\", \"OB\")]\n",
    "# add career percentages features for each pitch\n",
    "df = add_pitch_pct(df, career_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fast_pct</th>\n",
       "      <th>sinker_pct</th>\n",
       "      <th>slider_pct</th>\n",
       "      <th>curve_pct</th>\n",
       "      <th>changeup_pct</th>\n",
       "      <th>knuckle_pct</th>\n",
       "      <th>other_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "      <td>544741.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.521239</td>\n",
       "      <td>0.115370</td>\n",
       "      <td>0.140860</td>\n",
       "      <td>0.082819</td>\n",
       "      <td>0.108646</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.217422</td>\n",
       "      <td>0.201848</td>\n",
       "      <td>0.115913</td>\n",
       "      <td>0.081531</td>\n",
       "      <td>0.081837</td>\n",
       "      <td>0.092092</td>\n",
       "      <td>0.011917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.583994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145727</td>\n",
       "      <td>0.075859</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.668494</td>\n",
       "      <td>0.177795</td>\n",
       "      <td>0.225708</td>\n",
       "      <td>0.133868</td>\n",
       "      <td>0.164290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.982009</td>\n",
       "      <td>0.753546</td>\n",
       "      <td>0.613902</td>\n",
       "      <td>0.396465</td>\n",
       "      <td>0.345737</td>\n",
       "      <td>0.878311</td>\n",
       "      <td>0.232751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fast_pct     sinker_pct     slider_pct      curve_pct  \\\n",
       "count  544741.000000  544741.000000  544741.000000  544741.000000   \n",
       "mean        0.521239       0.115370       0.140860       0.082819   \n",
       "std         0.217422       0.201848       0.115913       0.081531   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.403816       0.000000       0.009494       0.000000   \n",
       "50%         0.583994       0.000000       0.145727       0.075859   \n",
       "75%         0.668494       0.177795       0.225708       0.133868   \n",
       "max         0.982009       0.753546       0.613902       0.396465   \n",
       "\n",
       "        changeup_pct    knuckle_pct      other_pct  \n",
       "count  544741.000000  544741.000000  544741.000000  \n",
       "mean        0.108646       0.021711       0.004775  \n",
       "std         0.081837       0.092092       0.011917  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.040486       0.000000       0.001358  \n",
       "50%         0.101254       0.000000       0.002689  \n",
       "75%         0.164290       0.000000       0.004878  \n",
       "max         0.345737       0.878311       0.232751  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"fast_pct\" : \"other_pct\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the pitch statistics that fastball is the most common type of pitch among all pitchers with some pitchers thrown almost entirely all fastball pitches. Although historical pitch percentages are useful in indicating a pitcher's tendency, we also need to consider the current batter that he faces. To do that, we'll add the historical pitch percentages of each type thrown by the pitcher to the current batter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_batter_pct(dff):\n",
    "    \"\"\"Compute pitcher's career percentages for each pitch type thrown at a specific batter.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    d: dictionary with (pitchcer_id, batter_id, pitch_type) as key and percentage as value\n",
    "    \"\"\"\n",
    "    x = dff.groupby([\"pitcher_id\", \"batter_id\"]).agg({\"pitch_type\": \"count\"})\n",
    "    y = dff.groupby([\"pitcher_id\", \"batter_id\", \"pitch_type\"]).agg({\"pitch_type\": \"count\"})\n",
    "    z = y.div(x, axis=1)\n",
    "    d = {}\n",
    "    for i in range(len(z)):\n",
    "        d[z.index[i]] = z.values[i][0]\n",
    "    return d\n",
    "\n",
    "def add_batter_pct(dff, btr_list):\n",
    "    \"\"\"Add careeer percentages features to dataframe.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    btr_list: list of 2-tuple strings representing pitch percentage specific to a batter.\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    dff: pd.DataFrame with added pitch percentages specific to a batter\n",
    "    \"\"\"\n",
    "    btr_pct = _get_batter_pct(dff)\n",
    "    temp = pd.Series(zip(dff.pitcher_id, dff.batter_id), index=dff.index)\n",
    "    for el in btr_list:\n",
    "        df[el[0]] = temp.map(lambda x: btr_pct.get((x[0], x[1], el[1]), 0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "btr_features = [(\"fast_btr\", \"FB\"), (\"sinker_btr\", \"SI\"), \n",
    "           (\"slider_btr\", \"SL\"), (\"curve_btr\", \"CU\"), \n",
    "           (\"changeup_btr\", \"CH\"), (\"knuckle_btr\", \"KB\"), \n",
    "           (\"other_btr\", \"OB\")]\n",
    "# add batter-specific percentages\n",
    "df = add_batter_pct(df, btr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous features captures the pitcher's overall tendency to favor a particular type of pitch. However, pitchers through practices in between games might modify their pitch tendency. Thus, it is important that we capture the pitcher's recent trend as well. This is done by adding a rolling 5, 10, 15, and 20 pitch percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_pct(dff, n, feats):\n",
    "    \"\"\"Compute n-recent pitch percentages for each pitch type.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    n: int representing number of recent pitches\n",
    "    feats: list of 2-tuple of feature names\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    dff: pd.DataFrame\n",
    "    \"\"\"\n",
    "    for feat in feats:\n",
    "        dff[feat[0] + \"_prev\" + str(n)] = (dff.groupby(\"pitcher_id\")[\"pitch_type\"].shift(1) == feat[1]).rolling(n).sum()/n\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "recent_features = [(\"fast\", \"FB\"), (\"sinker\", \"SI\"), (\"slider\", \"SL\"), \n",
    "                   (\"curve\", \"CU\"), (\"changeup\", \"CH\"), (\"knuckle\", \"KB\"), \n",
    "                   (\"other\", \"OB\")]\n",
    "# add 5, 10, 15, 20 recent percentages for each type\n",
    "for i in [5, 10, 15, 20]:\n",
    "    df = get_recent_pct(df, i, recent_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll get even more specific with the pitch percentages that capture a specific game scenario. For instance, facing a really good batter (i.e one with high home-run rate) with one runner on first base and the current ball/strike count is 3/0, the pitcher might be more inclined to walk the batter than attempting to strike him out. We need the percentages for each ball-strike count specific to a pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_combo_pct(dff):\n",
    "    \"\"\"Compute pitch type percentages for each ball-strike count specific to a pitcher.\n",
    "    params:\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    d: dictionary of (pitcher_id, ball-strike, pitch_type) tuple as key and percentages as value\n",
    "    \"\"\"\n",
    "    x = df.groupby([\"pitcher_id\", \"bs_count\"]).agg({\"pitch_type\": \"count\"})\n",
    "    y = df.groupby([\"pitcher_id\", \"bs_count\", \"pitch_type\"]).agg({\"pitch_type\": \"count\"})\n",
    "    z = y.div(x, axis=1)\n",
    "    d = {}\n",
    "    for i in range(len(z)):\n",
    "        d[z.index[i]] = z.values[i][0]\n",
    "    return d\n",
    "\n",
    "def add_combo_pct(dff, combo_list):\n",
    "    \"\"\"Add pitch type percentages for each ball-strike combo specific to a pitcher.\n",
    "    params:\n",
    "    -------\n",
    "    dff: pd.DataFrame\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    dff: pd.DataFrame with added features\n",
    "    \"\"\"\n",
    "    combo_pct = _get_combo_pct(dff)\n",
    "    temp = pd.Series(zip(dff.pitcher_id, dff.bs_count), index=dff.index)\n",
    "    pairs = [str(i)+str(j) for i in range(4) for j in range(3)]\n",
    "    for co in combo_list:\n",
    "        for pair in pairs:\n",
    "            dff[co[0] + pair + \"_combo\"] = temp.map(lambda x: combo_pct.get((x[0], x[1], co[1]), 0))\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# add ball-strike pitch percentages\n",
    "df = add_combo_pct(df, recent_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All engineered features added to the data set up to this point are based on information known prior to the pitch being thrown. Next, we will use post-pitch features (i.e., horizontal/vertical positions and velocity) to derive metrics that capture the recent tendency of a pitcher to throw in a particular pitch zone. We'll accompish this by taking a moving average of the previous three pitch coordinates and velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add previous coordinates and moving averages\n",
    "df[\"x_prev\"] = df.groupby(\"pitcher_id\")[\"x\"].shift(1)\n",
    "df[\"y_prev\"] = df.groupby(\"pitcher_id\")[\"y\"].shift(1)\n",
    "df[\"x_avg3\"] = df.groupby(\"pitcher_id\")[\"x\"].shift(1).rolling(3).mean()\n",
    "df[\"y_avg3\"] = df.groupby(\"pitcher_id\")[\"y\"].shift(1).rolling(3).mean()\n",
    "df[\"speed_prev\"] = df.groupby(\"pitcher_id\")[\"start_speed\"].shift(1)\n",
    "df[\"speed_avg3\"] = df.groupby(\"pitcher_id\")[\"start_speed\"].shift(1).rolling(3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the modeling process, let's first remove the `x` and `y` features which are information that are known only after the pitch is thrown. These two features were used to engineer the previous pitch coordinates as well as the average coordinates of the previous three pitches. Similarly, we will remove `start_speed` which indicates the velocity of the pitch. \n",
    "\n",
    "In addition, we need to shift the label column `pitch_type` backward since our goal is to forecast the next pitch. In its original form, the `pitch_type` label is only known after the pitch is made. Therefore, shifting backward one period avoids information leakage.\n",
    "\n",
    "After the above tasks is completed, we also need to drop all rows with NaN as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop after-pitch information\n",
    "df.drop([\"x\", \"y\", \"start_speed\"], axis=1, inplace=True)\n",
    "# drop rows with balls = 4\n",
    "df.drop(df[df.balls == 4].index, inplace=True)  # 2 rows dropped\n",
    "# shift label backward for forecasting\n",
    "df[\"pitch_type\"] = df.pitch_type.shift(-1)\n",
    "# drop NaN \n",
    "df.dropna(axis=0, inplace=True)\n",
    "len(df.batter_id.unique()) # 903 batters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "<h2>4. Classification Method</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is not to predict the next pitch but to *predict the next pitch given a specific ball/strike count*. We will use **Random Forest** method of classification for multiclass to predict the next pitch. But first, let's discuss the issues with the \"cleaned\" data set. There are over 903 unique batters in the record. Since `batter_id` is a categorical feature, if we are to **OneHot encode** this feature for our classfier, it will result in very high dimension, i.e., 903 features plus the rest of the other features. So we need to decide how to filter the batters such that we only keep the records of pitches related to frequent batters. Since there are 162 baseball games per season, it is assumed that frequent batters are those who get to bat at least twice per game. Thus, we will set the threshold to identify frequent batters at 400 and filter out pitches made to infrequent batters. Another issue to consider is that with 255 pitchers and 12 possible ball-strike count, there are 3060 subsets of data and models. However, not all subsets have large enough number of observations to train on. Some scenario are more likely than others (e.g., count 0-0 occur more frequently than 3-0 for some pitchers). So we will filter out scenario with subset data with fewer than 100. \n",
    "\n",
    "The two filters below result in 128 frequent batters and 778 pitcher and ball/strike combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [\"game_pk\", \"at_bat_num\", \"batter_id\"]\n",
    "bat_freq = df.drop_duplicates(mask).batter_id.value_counts() \n",
    "frequent_batters = bat_freq[bat_freq > 400].index  # 128 frequent batters\n",
    "df = df.loc[df.batter_id.isin(frequent_batters)]   # only keep pitch made to frequent batters\n",
    "df = df.groupby(\"pc_pair\").filter(lambda x: len(x) > 100)\n",
    "df.pc_pair.value_counts().shape[0]   # 778 subsets\n",
    "df.drop([\"game_pk\", \"bs_count\"], axis=1, inplace=True) # not used in forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be building 778 models for each pitcher and ball/strike combo, let's first subset the data. We'll put our subsets into a dictionary where the keys are pitcher and ball/strike count (i.e `pc_pair`) and the dictionary values are the subset dataframe specific to each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsets(dff):\n",
    "    \"\"\"Split dataframe into subsets of data based on pc_pair.\n",
    "    param:\n",
    "    ------\n",
    "    dff: pd.DataFrame\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    d: dictionary with pc_pair as key and pd.DataFrame as value\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for i in dff.pc_pair.unique():\n",
    "        d[i] = dff[dff.pc_pair == i]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 210 ms, total: 11.1 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create subsets of data\n",
    "subsets = get_subsets(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the identifier columns, the resulting data set contains 147 features -- 15 original and 132 engineered features that capture the historical pitch percentages and recent trend for each pitcher. This posses a problem of high dimensionality which could make it computationally expensive. So we will need to reduce the dimension to a more managable size. \n",
    "\n",
    "When it comes to dimensionality reduction, one well-known method comes to mind is **Principal Component Analysis (PCA)**. The loadings (coefficients) of each principal components are often use to select important features. However, *we will not use PCA method here*. This is because each pitcher is different and tend to favor a certain type of pitch. The problem gets more complicated as we consider the ball/strike count scenario which impact the pitcher's strategy. This mean a group of similar features that capture the historical pitch percentages and recent trend for fastballs may not be a useful in predicting pitchers who favor curveballs or sliders in a given ball/strike scenario. So we will need to select features by similar group for each pitcher and ball/strike combination. \n",
    "\n",
    "First, we'll create several lists of \"similar features\" to be used by the custom **ColumnSelector** to subset the dataframe. These features will be passed to a feature selection tool **FeatureSelector** which uses **LinearSVC** to reduce a given set of 18 features down to a smaller number. To deal with categorical features, we'll use the custom **FeatureHasher** to more efficiently encode the categories. These steps will be wrapped inside the **FeatureUnion** which combine the selected features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix = [\"_pct\", \"_btr\", \"_prev5\", \"_prev10\", \"_prev15\", \"_prev20\", \n",
    "           \"00_combo\", \"01_combo\", \"02_combo\", \n",
    "           \"10_combo\", \"11_combo\", \"12_combo\", \n",
    "           \"20_combo\", \"21_combo\", \"22_combo\",\n",
    "           \"30_combo\", \"31_combo\", \"32_combo\"]\n",
    "\n",
    "fast_features = [\"fast\" + pf for pf in postfix]\n",
    "sinker_features = [\"sinker\" + pf for pf in postfix]\n",
    "slider_features = [\"slider\" + pf for pf in postfix]\n",
    "curve_features = [\"curve\" + pf for pf in postfix]\n",
    "changeup_features = [\"changeup\" + pf for pf in postfix]\n",
    "knuckle_features = [\"fast\" + pf for pf in postfix]\n",
    "\n",
    "numeric_features = ['inning', 'top', 'at_bat_num', 'pcount_at_bat',\n",
    "                    'pcount_pitcher', 'balls', 'strikes', 'fouls', 'outs',\n",
    "                    'x_prev', 'y_prev', 'x_avg3', 'y_avg3', 'speed_prev', 'speed_avg3']\n",
    "\n",
    "categorical_features = [\"batter_id\", \"p_throws\", \"on_1b\", \"on_2b\", \"on_3b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select a subset of columns from the data set.\"\"\"\n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names   # columns is a list of column names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.col_names]\n",
    "\n",
    "class MyFeatureHasher(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Vecotrize a set of categorical variables.\"\"\"\n",
    "    def __init__(self, col_names, n_features=10):\n",
    "        self.col_names = col_names\n",
    "        self.n_features = n_features\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        data = X[self.col_names]\n",
    "        self.myvec = FeatureHasher(n_features=self.n_features)\n",
    "        self.myvec.fit(X[self.col_names].to_dict(orient='records'))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # vectorize input\n",
    "        return self.myvec.transform(X[self.col_names].to_dict(orient='records')).toarray()\n",
    "    \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    \n",
    "    # Use feature union to combine features selectors\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            \n",
    "            # pipeline for fastball features selector\n",
    "            ('fast', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=fast_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.9, penalty=\"l1\", dual=False)))\n",
    "            ])),\n",
    "            \n",
    "            # pipeline for sinker features selector\n",
    "            ('sinker', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=sinker_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.9, penalty=\"l1\", dual=False)))\n",
    "            ])), \n",
    "            \n",
    "            # pipeline for sinker features selector\n",
    "            ('slider', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=slider_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.75, penalty=\"l1\", dual=False)))\n",
    "            ])),\n",
    "            \n",
    "            # pipeline for curveball features selector\n",
    "            ('curve', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=curve_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.75, penalty=\"l1\", dual=False)))\n",
    "            ])), \n",
    "            \n",
    "            # pipeline for curveball features selector\n",
    "            ('changeup', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=changeup_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.75, penalty=\"l1\", dual=False)))\n",
    "            ])),\n",
    "            \n",
    "            # pipeline for curveball features selector\n",
    "            ('knuckle', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=knuckle_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.75, penalty=\"l1\", dual=False)))\n",
    "            ])),\n",
    "            \n",
    "            # pipeline for numeric features selector\n",
    "            ('numeric', Pipeline([\n",
    "                ('selector', ColumnSelector(col_names=numeric_features)),\n",
    "                ('feature_selection', SelectFromModel(LinearSVC(C=0.75, penalty=\"l1\", dual=False)))\n",
    "            ])),\n",
    "                      \n",
    "            # pipeline for categorical features hasher\n",
    "            ('hash', Pipeline([\n",
    "                ('feature_hasher', MyFeatureHasher(col_names=categorical_features, n_features=100)) # 128 + 8 categories\n",
    "            ]))\n",
    "        ]\n",
    "    )),\n",
    "    \n",
    "#   # use RandomForest classifier on combined features\n",
    "    ('rfc', RandomForestClassifier(n_estimators=20, max_depth=20, \n",
    "                                   class_weight='balanced', random_state=random_state))\n",
    "    \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'union__hash__feature_hasher__n_features': [75, 100, 125],\n",
    "    'rfc__n_estimators': range(20, 40, 60),\n",
    "    'rfc__max_depth': range(10, 20, 30)\n",
    "}\n",
    "\n",
    "%time\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, iid=False)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print((\"best random forest from grid search: %.3f\" % grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a pipeline built out, we will train all 778 models and store the result in a dictionary for forecasting purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='res'></a>\n",
    "<h2>5. Results</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build out 778 different models specific to each pitcher-count combination, we use the block of code below to store the models in adictionary. Of course we do not want to re-run all 778 models in real-time as we only need one one them. Therefore, we can save our model in a dictionary where the keys are pitcher-count combinations and the dictionary values are tuples which hold the fitted model, as well as the train and test data. Then we pickle the models for use at a later time. \n",
    "\n",
    "The block of code below (commented out) does just that but it will take a while to train and test all 778 models. However for demostration purpose, we'll use the pipeline above to test the model prediction of one of the 778 subsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subsets[\"434378_12\"].drop(\"pitch_type\", axis=1)\n",
    "y = subsets[\"434378_12\"].pitch_type\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FB', 'FB', 'FB', 'FB', 'FB', 'CH', 'FB', 'FB', 'FB', 'CU', 'FB',\n",
       "       'FB', 'CU', 'FB', 'FB', 'FB', 'CU', 'FB', 'FB', 'FB', 'CU', 'FB',\n",
       "       'FB', 'FB', 'CU', 'FB', 'CH', 'CU', 'CU', 'FB', 'CU', 'SL', 'FB',\n",
       "       'CU', 'FB', 'FB', 'FB', 'FB', 'CU', 'FB', 'FB', 'CH', 'FB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3 , 0.25, 0.4 , 0.  , 0.05],\n",
       "       [0.  , 0.35, 0.45, 0.1 , 0.1 ],\n",
       "       [0.05, 0.  , 0.8 , 0.  , 0.15]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# models = {}\n",
    "# for k, v in subsets.items():\n",
    "#     X = v.drop(\"pitch_type\", axis=1)\n",
    "#     y = v.pitch_type\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#     models[k] = (grid_search.fit(X_train, y_train), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle the results\n",
    "# filename = \"final_models.sav\"\n",
    "# pickle.dump(models, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unpickle the saved data\n",
    "# filename = \"final_models.sav\"\n",
    "# models = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='futures'></a>\n",
    "<h2>Future Consideration</h2>\n",
    "\n",
    "For future work, I would like to consider additional factors such as time of the day the pitch was made and whether the morning or evening have different impact on the type of pitch thrown by a pitcher. However, without talking to an expert in the field, I cannot ascertain whether it is an important factor. Additionally, I would like to consider the `type_confidence` feature from the data set as a predictor. However, I am not sure how this number is measured for now as some of the confidence exceed 1. I also would like to consider the current score as I think it definitely impact the pitch strategy. However, from the given metadata csv file, it is not clear whether that information is contained in the data set. \n",
    "\n",
    "With respect to programming code, the commented out code block above builds 778 models and save them in a dictionary to be access later via pickling. This process takes a long time and can be improved with **multiprocessing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix'></a>\n",
    "<h2>Appendix</h2>\n",
    "\n",
    "* Original features\n",
    "    - Inning\n",
    "    - Top\n",
    "    - At-bat-number\n",
    "    - Pitches thrown at bat\n",
    "    - Pitches thrown by pitcher\n",
    "    - Balls and strikes count\n",
    "    - Current number of fouls and outs\n",
    "    - Batter and pitcher identifications\n",
    "    - Hand pitcher throw with\n",
    "    - (x, y) horizontal and vertical position of a pitch\n",
    "    - Start-speed or velocity of the pitch\n",
    "    - Pitch type\n",
    "    - On-first base\n",
    "    - On-second base\n",
    "    - On-third base\n",
    "* Engineered features (132 added)\n",
    "    - Historical pitch percentage for each type of pitch (fast, sinker, slider, etc.) for each pitcher\n",
    "    - Historical pitch percentage for each type thrown by the pitcher to the current batter\n",
    "    - Pitch percentage for each type type thrown by the pitcher in a given ball-strike count scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
